// lib/services/audio_playback_service.dart

import 'dart:async';
import 'dart:convert';
import 'dart:io' show File, Platform;
import 'dart:typed_data';
import 'package:flutter/foundation.dart';
import 'package:dio/dio.dart';

import 'package:flutter_dotenv/flutter_dotenv.dart';
import 'package:path_provider/path_provider.dart';
import '../utils/audio_utils.dart';
import '../core/logger.dart';

// Conditional import for web
import 'dart:html' as html if (dart.library.io) 'dart:io' as html;

class AudioPlaybackService {
  final AudioPlayer _audioPlayer = AudioPlayer();
  final Dio _dio;
  final String _apiKey;
  
  // ìŒì„± ì˜µì…˜
  static const List<String> VOICES = ['nova', 'alloy', 'echo', 'fable', 'onyx', 'shimmer'];
  static const Map<String, double> SPEED_OPTIONS = {
    'slow': 0.75,
    'normal': 0.95,
    'fast': 1.15,
  };
  
  // ìºì‹œ (ë©”ëª¨ë¦¬)
  final Map<String, Uint8List> _audioCache = {};
  static const int MAX_CACHE_SIZE = 20; // ìµœëŒ€ 20ê°œ ìºì‹œ
  
  AudioPlaybackService() : 
    _apiKey = dotenv.env['OPENAI_API_KEY'] ?? '',
    _dio = Dio(BaseOptions(
      baseUrl: 'https://api.openai.com/v1',
      connectTimeout: const Duration(seconds: 30),
      receiveTimeout: const Duration(seconds: 60),
      headers: {
        'Authorization': 'Bearer ${dotenv.env['OPENAI_API_KEY'] ?? ''}',
      },
    ));
  
  // 1. TTS ìƒì„± ë° ì¬ìƒ (ê³ í’ˆì§ˆ)
  Future<void> speakHighQuality({
    required String text,
    String voice = 'nova',
    double speed = 0.95,
    Function()? onComplete,
    Function(String)? onError,
  }) async {
    try {
      // ìºì‹œ í™•ì¸
      final cacheKey = _getCacheKey(text, voice, speed);
      
      Uint8List audioData;
      if (_audioCache.containsKey(cacheKey)) {
        audioData = _audioCache[cacheKey]!;
        print('ğŸµ Using cached audio');
      } else {
        // OpenAI TTS-HD API í˜¸ì¶œ
        audioData = await _generateTTS(text, voice, speed);
        _addToCache(cacheKey, audioData);
      }
      
      // í”Œë«í¼ë³„ ì¬ìƒ
      if (kIsWeb) {
        await _playOnWeb(audioData);
      } else {
        await _playOnMobile(audioData);
      }
      
      onComplete?.call();
      
    } catch (e) {
      print('âŒ Audio playback error: $e');
      onError?.call(e.toString());
    }
  }
  
  // 2. TTS ìƒì„±
  Future<Uint8List> _generateTTS(String text, String voice, double speed) async {
    try {
      final response = await _dio.post(
        '/audio/speech',
        options: Options(responseType: ResponseType.bytes),
        data: {
          'model': 'tts-1-hd',
          'voice': voice,
          'input': text,
          'speed': speed,
        },
      );
      
      return Uint8List.fromList(response.data);
      
    } catch (e) {
      print('âŒ TTS generation error: $e');
      throw Exception('Failed to generate audio: $e');
    }
  }
  
  // 3. ì›¹ì—ì„œ ì¬ìƒ
  Future<void> _playOnWeb(Uint8List audioData) async {
    try {
      // Blob ìƒì„±
      final blob = html.Blob([audioData], 'audio/mp3');
      final url = html.Url.createObjectUrlFromBlob(blob);
      
      // Audio ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„± ë° ì¬ìƒ
      final audio = html.AudioElement()
        ..src = url
        ..autoplay = false
        ..volume = 0.9;
      
      // ì¬ìƒ
      await audio.play();
      
      // ì¬ìƒ ì™„ë£Œ ëŒ€ê¸°
      await audio.onEnded.first;
      
      // ë©”ëª¨ë¦¬ ì •ë¦¬
      html.Url.revokeObjectUrl(url);
      
    } catch (e) {
      print('âŒ Web audio playback error: $e');
      throw e;
    }
  }
  
  // 4. ëª¨ë°”ì¼ì—ì„œ ì¬ìƒ (iOS í˜¸í™˜)
  Future<void> _playOnMobile(Uint8List audioData) async {
    File? tempFile;
    
    try {
      // iOSì—ì„œëŠ” ì„ì‹œ íŒŒì¼ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ì•ˆì •ì 
      if (!kIsWeb && Platform.isIOS) {
        // ì„ì‹œ ë””ë ‰í† ë¦¬ì— íŒŒì¼ ìƒì„±
        final tempDir = await getTemporaryDirectory();
        final timestamp = DateTime.now().millisecondsSinceEpoch;
        tempFile = File('${tempDir.path}/tts_audio_$timestamp.mp3');
        
        // ì˜¤ë””ì˜¤ ë°ì´í„° ì“°ê¸°
        await tempFile.writeAsBytes(audioData);
        
        // íŒŒì¼ë¡œë¶€í„° ì˜¤ë””ì˜¤ ì†ŒìŠ¤ ì„¤ì •
        await _audioPlayer.setFilePath(tempFile.path);
        await _audioPlayer.play();
        await _audioPlayer.playerStateStream.firstWhere(
          (state) => state.processingState == ProcessingState.completed,
        );
        
        // ì¬ìƒ ì™„ë£Œ í›„ íŒŒì¼ ì‚­ì œ
        if (tempFile.existsSync()) {
          tempFile.deleteSync();
        }
      } else {
        // Android ë˜ëŠ” ë‹¤ë¥¸ í”Œë«í¼: Data URI ì‚¬ìš©
        final audioSource = AudioSource.uri(
          Uri.dataFromBytes(audioData, mimeType: 'audio/mp3'),
        );
        
        await _audioPlayer.setAudioSource(audioSource);
        await _audioPlayer.play();
        await _audioPlayer.playerStateStream.firstWhere(
          (state) => state.processingState == ProcessingState.completed,
        );
      }
      
    } catch (e) {
      // ì‹¤íŒ¨ ì‹œ ì„ì‹œ íŒŒì¼ ì •ë¦¬
      if (tempFile != null && tempFile.existsSync()) {
        tempFile.deleteSync();
      }
      print('âŒ Mobile audio playback error: $e');
      throw e;
    }
  }
  
  // 5. ëŒ€í™” ì „ì²´ ì¬ìƒ (Upgrade Replayìš©)
  Future<void> playConversationSequence(
    List<Map<String, String>> conversation, {
    Map<String, String>? improvedUserResponses,
    Function(int)? onProgressUpdate,
    Function()? onComplete,
  }) async {
    try {
      for (int i = 0; i < conversation.length; i++) {
        final turn = conversation[i];
        
        onProgressUpdate?.call(i);
        
        if (turn['speaker'] == 'AI') {
          // AI ìŒì„±ì€ ì›ë³¸ ê·¸ëŒ€ë¡œ
          await speakHighQuality(
            text: turn['text']!,
            voice: 'nova',
            speed: 0.95,
          );
        } else {
          // User ìŒì„±ì€ ê°œì„ ëœ ë²„ì „ ì‚¬ìš© (ìˆìœ¼ë©´)
          final textToSpeak = improvedUserResponses?[turn['text']!] ?? turn['text']!;
          await speakHighQuality(
            text: textToSpeak,
            voice: 'echo', // ì‚¬ìš©ìëŠ” ë‹¤ë¥¸ ìŒì„±
            speed: 0.9,
          );
        }
        
        // í„´ ì‚¬ì´ ìì—°ìŠ¤ëŸ¬ìš´ ê°„ê²©
        await Future.delayed(const Duration(milliseconds: 800));
      }
      
      onComplete?.call();
      
    } catch (e) {
      print('âŒ Conversation playback error: $e');
      throw e;
    }
  }
  
  // 6. ì •ì§€
  Future<void> stop() async {
    if (!kIsWeb) {
      await _audioPlayer.stop();
    }
  }
  
  // 7. ì¼ì‹œì •ì§€
  Future<void> pause() async {
    if (!kIsWeb) {
      await _audioPlayer.pause();
    }
  }
  
  // 8. ì¬ê°œ
  Future<void> resume() async {
    if (!kIsWeb) {
      await _audioPlayer.play();
    }
  }
  
  // 9. ë³¼ë¥¨ ì¡°ì ˆ
  Future<void> setVolume(double volume) async {
    if (!kIsWeb) {
      await _audioPlayer.setVolume(volume.clamp(0.0, 1.0));
    }
  }
  
  // 10. ìºì‹œ ê´€ë¦¬
  String _getCacheKey(String text, String voice, double speed) {
    return '${text.hashCode}_${voice}_$speed';
  }
  
  void _addToCache(String key, Uint8List data) {
    // ìºì‹œ í¬ê¸° ì œí•œ
    if (_audioCache.length >= MAX_CACHE_SIZE) {
      // ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±° (FIFO)
      _audioCache.remove(_audioCache.keys.first);
    }
    _audioCache[key] = data;
  }
  
  void clearCache() {
    _audioCache.clear();
  }
  
  // 11. PCM ì˜¤ë””ì˜¤ ì¬ìƒ (OpenAI Realtime APIìš©)
  Future<void> playPCMAudio(String base64PCM) async {
    try {
      // PCMì„ WAVë¡œ ë³€í™˜
      final wavData = AudioUtils.base64PcmToWav(base64PCM);
      
      if (kIsWeb) {
        await _playOnWeb(wavData);
      } else {
        await _playPCMOnMobile(wavData);
      }
    } catch (e) {
      AppLogger.error('Failed to play PCM audio', e);
    }
  }
  
  // 12. ëª¨ë°”ì¼ì—ì„œ PCM/WAV ì¬ìƒ (iOS í˜¸í™˜)
  Future<void> _playPCMOnMobile(Uint8List wavData) async {
    File? tempFile;
    
    try {
      // ì„ì‹œ ë””ë ‰í† ë¦¬ì— WAV íŒŒì¼ ìƒì„±
      final tempDir = await getTemporaryDirectory();
      final timestamp = DateTime.now().millisecondsSinceEpoch;
      tempFile = File('${tempDir.path}/pcm_audio_$timestamp.wav');
      
      // WAV ë°ì´í„° ì“°ê¸°
      await tempFile.writeAsBytes(wavData);
      
      // íŒŒì¼ë¡œë¶€í„° ì˜¤ë””ì˜¤ ì†ŒìŠ¤ ì„¤ì •
      await _audioPlayer.setFilePath(tempFile.path);
      await _audioPlayer.play();
      
      // ì¬ìƒ ì™„ë£Œ í›„ íŒŒì¼ ì‚­ì œ ì˜ˆì•½ (5ì´ˆ í›„)
      Timer(const Duration(seconds: 5), () {
        if (tempFile != null && tempFile.existsSync()) {
          try {
            tempFile.deleteSync();
            AppLogger.debug('Deleted temp audio file: ${tempFile.path}');
          } catch (e) {
            AppLogger.warning('Failed to delete temp file: ${tempFile.path}');
          }
        }
      });
      
    } catch (e) {
      // ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ íŒŒì¼ ì‚­ì œ
      if (tempFile != null && tempFile.existsSync()) {
        tempFile.deleteSync();
      }
      AppLogger.error('PCM audio playback failed', e);
    }
  }
  
  // 13. ë¦¬ì†ŒìŠ¤ í•´ì œ
  void dispose() {
    _audioPlayer.dispose();
    clearCache();
  }
}