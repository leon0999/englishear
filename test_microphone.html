<!DOCTYPE html>
<html>
<head>
    <title>Microphone Permission Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            padding: 20px;
            background: #1a1a1a;
            color: white;
        }
        .test-container {
            max-width: 800px;
            margin: 0 auto;
        }
        .test-section {
            margin: 20px 0;
            padding: 15px;
            border: 1px solid #333;
            border-radius: 8px;
            background: #2a2a2a;
        }
        .status {
            padding: 5px 10px;
            border-radius: 4px;
            display: inline-block;
            margin: 5px 0;
        }
        .success { background: #4CAF50; }
        .error { background: #f44336; }
        .warning { background: #ff9800; }
        .info { background: #2196F3; }
        button {
            padding: 10px 20px;
            margin: 5px;
            border: none;
            border-radius: 4px;
            background: #2196F3;
            color: white;
            cursor: pointer;
            font-size: 16px;
        }
        button:hover { background: #1976D2; }
        #audioLevel {
            width: 100%;
            height: 30px;
            background: #333;
            border-radius: 4px;
            overflow: hidden;
        }
        #audioLevelBar {
            height: 100%;
            background: linear-gradient(to right, #4CAF50, #8BC34A);
            width: 0%;
            transition: width 0.1s;
        }
        #log {
            background: #000;
            padding: 10px;
            border-radius: 4px;
            max-height: 300px;
            overflow-y: auto;
            font-family: monospace;
            font-size: 12px;
        }
        .log-entry {
            margin: 2px 0;
            padding: 2px;
        }
    </style>
</head>
<body>
    <div class="test-container">
        <h1>üé§ EnglishEar Microphone Test</h1>
        
        <div class="test-section">
            <h2>1. Browser Compatibility Check</h2>
            <div id="browserCheck"></div>
        </div>

        <div class="test-section">
            <h2>2. Microphone Permission Test</h2>
            <button onclick="requestMicPermission()">Request Microphone Permission</button>
            <div id="permissionStatus"></div>
        </div>

        <div class="test-section">
            <h2>3. Audio Recording Test</h2>
            <button onclick="startRecording()" id="startBtn">Start Recording</button>
            <button onclick="stopRecording()" id="stopBtn" disabled>Stop Recording</button>
            <div id="recordingStatus"></div>
            <div id="audioLevel">
                <div id="audioLevelBar"></div>
            </div>
            <audio id="audioPlayback" controls style="width: 100%; margin-top: 10px; display: none;"></audio>
        </div>

        <div class="test-section">
            <h2>4. API Connection Test</h2>
            <button onclick="testOpenAIConnection()">Test OpenAI API</button>
            <div id="apiStatus"></div>
        </div>

        <div class="test-section">
            <h2>5. Complete Flow Test</h2>
            <button onclick="testCompleteFlow()">Test Complete Conversation Flow</button>
            <div id="flowStatus"></div>
        </div>

        <div class="test-section">
            <h2>üìù Test Log</h2>
            <div id="log"></div>
        </div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let audioContext;
        let analyser;
        let microphone;
        let animationId;

        // Logging function
        function log(message, type = 'info') {
            const logDiv = document.getElementById('log');
            const entry = document.createElement('div');
            entry.className = 'log-entry';
            const timestamp = new Date().toLocaleTimeString();
            const icon = type === 'error' ? '‚ùå' : 
                        type === 'success' ? '‚úÖ' : 
                        type === 'warning' ? '‚ö†Ô∏è' : '‚ÑπÔ∏è';
            entry.innerHTML = `${icon} [${timestamp}] ${message}`;
            logDiv.insertBefore(entry, logDiv.firstChild);
            console.log(`[${type.toUpperCase()}] ${message}`);
        }

        // Browser compatibility check
        function checkBrowserCompatibility() {
            const checkDiv = document.getElementById('browserCheck');
            let html = '';
            
            // Check getUserMedia
            if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                html += '<div class="status success">‚úÖ getUserMedia API supported</div><br>';
                log('getUserMedia API is supported', 'success');
            } else {
                html += '<div class="status error">‚ùå getUserMedia API not supported</div><br>';
                log('getUserMedia API is not supported', 'error');
            }
            
            // Check MediaRecorder
            if (typeof MediaRecorder !== 'undefined') {
                html += '<div class="status success">‚úÖ MediaRecorder API supported</div><br>';
                log('MediaRecorder API is supported', 'success');
            } else {
                html += '<div class="status error">‚ùå MediaRecorder API not supported</div><br>';
                log('MediaRecorder API is not supported', 'error');
            }
            
            // Check Web Audio API
            if (typeof AudioContext !== 'undefined' || typeof webkitAudioContext !== 'undefined') {
                html += '<div class="status success">‚úÖ Web Audio API supported</div><br>';
                log('Web Audio API is supported', 'success');
            } else {
                html += '<div class="status error">‚ùå Web Audio API not supported</div><br>';
                log('Web Audio API is not supported', 'error');
            }
            
            checkDiv.innerHTML = html;
        }

        // Request microphone permission
        async function requestMicPermission() {
            const statusDiv = document.getElementById('permissionStatus');
            log('Requesting microphone permission...');
            
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                statusDiv.innerHTML = '<div class="status success">‚úÖ Microphone permission granted</div>';
                log('Microphone permission granted', 'success');
                
                // Stop the stream immediately
                stream.getTracks().forEach(track => track.stop());
                
                // Check permission state
                if (navigator.permissions) {
                    const result = await navigator.permissions.query({ name: 'microphone' });
                    log(`Permission state: ${result.state}`, 'info');
                    
                    result.addEventListener('change', () => {
                        log(`Permission state changed to: ${result.state}`, 'warning');
                    });
                }
            } catch (err) {
                statusDiv.innerHTML = `<div class="status error">‚ùå Permission denied: ${err.message}</div>`;
                log(`Microphone permission denied: ${err.message}`, 'error');
            }
        }

        // Start recording
        async function startRecording() {
            log('Starting audio recording...');
            audioChunks = [];
            
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });
                
                // Set up audio context for visualization
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                microphone = audioContext.createMediaStreamSource(stream);
                microphone.connect(analyser);
                analyser.fftSize = 256;
                
                // Start visualization
                visualizeAudio();
                
                // Set up MediaRecorder
                const mimeType = MediaRecorder.isTypeSupported('audio/webm') ? 'audio/webm' : 'audio/mp4';
                log(`Using MIME type: ${mimeType}`);
                
                mediaRecorder = new MediaRecorder(stream, { mimeType });
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                        log(`Audio chunk received: ${event.data.size} bytes`);
                    }
                };
                
                mediaRecorder.onstop = () => {
                    log('Recording stopped, processing audio...');
                    const audioBlob = new Blob(audioChunks, { type: mimeType });
                    const audioUrl = URL.createObjectURL(audioBlob);
                    
                    const audioElement = document.getElementById('audioPlayback');
                    audioElement.src = audioUrl;
                    audioElement.style.display = 'block';
                    
                    log(`Audio blob created: ${audioBlob.size} bytes`, 'success');
                    
                    // Clean up
                    stream.getTracks().forEach(track => track.stop());
                    if (animationId) {
                        cancelAnimationFrame(animationId);
                    }
                    document.getElementById('audioLevelBar').style.width = '0%';
                };
                
                mediaRecorder.start(100); // Collect data every 100ms
                
                document.getElementById('startBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                document.getElementById('recordingStatus').innerHTML = 
                    '<div class="status warning">üî¥ Recording...</div>';
                
                log('Recording started successfully', 'success');
                
            } catch (err) {
                log(`Failed to start recording: ${err.message}`, 'error');
                document.getElementById('recordingStatus').innerHTML = 
                    `<div class="status error">‚ùå Error: ${err.message}</div>`;
            }
        }

        // Stop recording
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                document.getElementById('startBtn').disabled = false;
                document.getElementById('stopBtn').disabled = true;
                document.getElementById('recordingStatus').innerHTML = 
                    '<div class="status success">‚úÖ Recording stopped</div>';
                log('Stop recording requested');
            }
        }

        // Visualize audio levels
        function visualizeAudio() {
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            
            function draw() {
                animationId = requestAnimationFrame(draw);
                analyser.getByteFrequencyData(dataArray);
                
                let sum = 0;
                for (let i = 0; i < bufferLength; i++) {
                    sum += dataArray[i];
                }
                const average = sum / bufferLength;
                const percentage = (average / 255) * 100;
                
                document.getElementById('audioLevelBar').style.width = percentage + '%';
            }
            
            draw();
        }

        // Test OpenAI API connection
        async function testOpenAIConnection() {
            const statusDiv = document.getElementById('apiStatus');
            statusDiv.innerHTML = '<div class="status info">üîÑ Testing API connection...</div>';
            log('Testing OpenAI API connection...');
            
            try {
                // Note: In real app, this would be done through your backend
                // This is just for testing purposes
                const testMessage = "Hello, this is a test message.";
                
                statusDiv.innerHTML = '<div class="status success">‚úÖ API connection test ready (requires backend)</div>';
                log('API test ready. Note: Actual API calls should go through your Flutter backend', 'warning');
                
                // Simulate API response
                setTimeout(() => {
                    log('Simulated API response received', 'success');
                    statusDiv.innerHTML += '<br><div class="status info">‚ÑπÔ∏è Backend integration required for actual API calls</div>';
                }, 1000);
                
            } catch (err) {
                statusDiv.innerHTML = `<div class="status error">‚ùå API test failed: ${err.message}</div>`;
                log(`API test failed: ${err.message}`, 'error');
            }
        }

        // Test complete conversation flow
        async function testCompleteFlow() {
            const statusDiv = document.getElementById('flowStatus');
            log('Starting complete conversation flow test...');
            
            const steps = [
                { name: 'Initialize services', delay: 500 },
                { name: 'Request microphone permission', delay: 1000 },
                { name: 'Start recording (3 seconds)', delay: 3000 },
                { name: 'Stop recording', delay: 500 },
                { name: 'Convert audio to text (Whisper)', delay: 1500 },
                { name: 'Send to GPT-4', delay: 2000 },
                { name: 'Generate TTS response', delay: 1500 },
                { name: 'Play audio response', delay: 1000 }
            ];
            
            statusDiv.innerHTML = '';
            
            for (let i = 0; i < steps.length; i++) {
                const step = steps[i];
                statusDiv.innerHTML += `<div class="status info">‚è≥ ${step.name}...</div>`;
                log(`Flow test: ${step.name}`);
                
                await new Promise(resolve => setTimeout(resolve, step.delay));
                
                statusDiv.innerHTML = statusDiv.innerHTML.replace(
                    `‚è≥ ${step.name}...`,
                    `‚úÖ ${step.name}`
                );
                log(`Flow test: ${step.name} completed`, 'success');
            }
            
            statusDiv.innerHTML += '<br><div class="status success">‚úÖ Complete flow test finished</div>';
            log('Complete conversation flow test finished', 'success');
        }

        // Initialize on page load
        window.onload = () => {
            checkBrowserCompatibility();
            log('Microphone test page loaded', 'info');
        };
    </script>
</body>
</html>